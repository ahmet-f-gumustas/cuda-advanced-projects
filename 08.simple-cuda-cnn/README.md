# ğŸš€ Simple CUDA CNN

CUDA ve C++ ile yazÄ±lmÄ±ÅŸ basit bir CNN (Convolutional Neural Network) uygulamasÄ±. Proje, CUDA kernellerini `.so` shared library olarak derleyip Python'dan kullanmayÄ± gÃ¶sterir.

## ğŸ“‹ Ã–zellikler

- **2D Convolution** - 3x3 filtre ile convolution iÅŸlemi
- **ReLU Activation** - Non-linear activation function
- **Max Pooling** - 2x2 pooling operasyonu
- **Python Bindings** - ctypes ile Python entegrasyonu

## ğŸ—ï¸ Mimari

```
Input (HxW)
    â†“
Convolution 3x3 â†’ (H-2)x(W-2)
    â†“
ReLU Activation
    â†“
Max Pooling 2x2 â†’ (H-2)/2 x (W-2)/2
    â†“
Output
```

## ğŸ“‚ Proje YapÄ±sÄ±

```
08.simple-cuda-cnn/
â”œâ”€â”€ CMakeLists.txt          # Build konfigÃ¼rasyonu
â”œâ”€â”€ include/
â”‚   â””â”€â”€ cnn_cuda.h         # C/C++ header dosyasÄ±
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cnn_kernels.cu     # CUDA kernel implementasyonlarÄ±
â”‚   â””â”€â”€ cnn_wrapper.cpp    # C++ wrapper API
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ demo.py            # Ana demo scripti
â”‚   â””â”€â”€ test_simple.py     # Basit test scripti
â””â”€â”€ build/                 # Build output (libcnn_cuda.so)
```

## ğŸ”§ Gereksinimler

- CUDA Toolkit (>= 11.0)
- CMake (>= 3.18)
- GCC/G++ compiler
- Python 3.x
- NumPy

## âš™ï¸ Kurulum ve Build

### 1. Projeyi Build Et

```bash
cd 08.simple-cuda-cnn
mkdir -p build
cd build
cmake ..
make
```

Bu komut `build/libcnn_cuda.so` dosyasÄ±nÄ± oluÅŸturur.

### 2. Build'i Kontrol Et

```bash
ls -lh build/libcnn_cuda.so
```

## ğŸ® KullanÄ±m

### Demo Script'ini Ã‡alÄ±ÅŸtÄ±r

```bash
cd 08.simple-cuda-cnn
python3 python/demo.py
```

**Ã‡Ä±ktÄ± Ã¶rneÄŸi:**
```
============================================================
CUDA CNN Demo - Basit Convolution + ReLU + MaxPooling
============================================================

1. CNN Context oluÅŸturuluyor (10x10 input)...
2. Input verisi hazÄ±rlanÄ±yor...
3. 3x3 Filter hazÄ±rlanÄ±yor (edge detection)...
4. Veriler GPU'ya aktarÄ±lÄ±yor...
5. CNN Forward Pass Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...
   - Convolution (3x3)
   - ReLU Activation
   - Max Pooling (2x2)

   âš¡ Inference PerformansÄ±:
      GPU Kernel Time: 0.0195 ms
      Total Time:      0.0312 ms
      Throughput:      51398.03 FPS

6. SonuÃ§lar GPU'dan alÄ±nÄ±yor...
7. SonuÃ§lar:
   Output shape: (4, 4)
   Output deÄŸerleri:
   [[...]]
8. Benchmark (10 iterasyon)...
   Ortalama: 0.0194 ms (Â±0.0016)
   Min:      0.0184 ms
   Max:      0.0239 ms
   FPS:      51516.65
9. Kaynaklar temizleniyor...
============================================================
Demo baÅŸarÄ±yla tamamlandÄ±! âœ“
============================================================
```

### Basit Test

```bash
python3 python/test_simple.py
```

## ğŸ“Š Teknik Detaylar

### CUDA Kernels

1. **conv2d_kernel**: 2D convolution operasyonu
   - 3x3 filter boyutu
   - Thread per pixel paralelizasyon
   - 16x16 thread block boyutu

2. **relu_kernel**: ReLU activation
   - Element-wise operasyon
   - `f(x) = max(0, x)`
   - 256 thread per block

3. **max_pool_kernel**: Max pooling
   - 2x2 pooling window
   - Stride = 2
   - 16x16 thread block boyutu

### Memory Management

- GPU memory allocation: `cudaMalloc`
- Host-Device transfer: `cudaMemcpy`
- Otomatik cleanup: `destroy_cnn_context`

### Performance Timing

- **CUDA Events**: GPU kernel execution time Ã¶lÃ§Ã¼mÃ¼
- **Precision**: Milisaniye (ms) cinsinden
- **Warmup**: Ä°lk Ã§alÄ±ÅŸtÄ±rma sonrasÄ± stabil timing
- **Benchmark**: Ã‡oklu iterasyonla ortalama/std hesaplama

### Python Entegrasyonu

- **ctypes** ile C library binding
- NumPy array'leri GPU'ya transfer
- Zero-copy pointer passing

## ğŸ”¬ Ã–rnek KullanÄ±m

```python
import ctypes
import numpy as np

# KÃ¼tÃ¼phaneyi yÃ¼kle
lib = ctypes.CDLL('./build/libcnn_cuda.so')

# Context oluÅŸtur
ctx = lib.create_cnn_context(10, 10)

# Input ve filter hazÄ±rla
input_data = np.random.randn(10, 10).astype(np.float32)
filter_data = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float32)

# GPU'ya aktar
lib.set_input_data(ctx, input_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)), 100)
lib.set_filter_data(ctx, filter_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)), 9)

# Forward pass
lib.run_cnn_forward(ctx)

# Timing bilgisini al
inference_time_ms = lib.get_last_inference_time(ctx)
print(f"Inference time: {inference_time_ms:.4f} ms")

# SonuÃ§larÄ± al
output = np.zeros(16, dtype=np.float32)  # 4x4
lib.get_output_data(ctx, output.ctypes.data_as(ctypes.POINTER(ctypes.c_float)), 16)

# Temizle
lib.destroy_cnn_context(ctx)
```

## ğŸ“ˆ Performans

### Benchmark SonuÃ§larÄ± (10x10 input)

```
Input Size:  10x10
Output Size: 4x4 (after conv + pool)

GPU Kernel Time:  ~0.019 ms
Throughput:       ~51,000 FPS
Min/Max Variance: Â±0.002 ms
```

### Optimizasyonlar

- **GPU Parallelizasyon**: TÃ¼m operasyonlar CUDA kernels ile paralel
- **Memory Coalescing**: Optimized memory access patterns
- **Synchronization**: Kernel sonrasÄ± otomatik sync
- **Timing**: CUDA Events ile hassas Ã¶lÃ§Ã¼m

## ğŸ§ª Test

```bash
# Basit test
python3 python/test_simple.py

# DetaylÄ± demo
python3 python/demo.py
```

## ğŸ› Troubleshooting

**Hata: libcnn_cuda.so bulunamadÄ±**
```bash
# Build klasÃ¶rÃ¼nÃ¼ kontrol et
ls build/libcnn_cuda.so

# Tekrar build et
cd build && cmake .. && make
```

**CUDA Runtime Error**
```bash
# CUDA kurulumunu kontrol et
nvcc --version

# GPU varlÄ±ÄŸÄ±nÄ± test et
nvidia-smi
```

## ğŸ“ Notlar

- Bu basit bir demo projesidir
- GerÃ§ek CNN eÄŸitimi iÃ§in PyTorch/TensorFlow kullanÄ±n
- Backpropagation implementasyonu yok
- Tek channel (grayscale) destekler

## ğŸš€ GeniÅŸletme Ä°mkanlarÄ±

1. **Multi-channel support** - RGB images iÃ§in
2. **Batch processing** - Ã‡oklu image processing
3. **Backward pass** - Gradient hesaplama
4. **Optimizasyon** - Shared memory kullanÄ±mÄ±
5. **Daha fazla layer** - Fully connected, dropout, etc.

## ğŸ“š Kaynaklar

- [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [CNN Fundamentals](https://cs231n.github.io/)

---

**GeliÅŸtirici**: CUDA Advanced Projects
**Lisans**: MIT
