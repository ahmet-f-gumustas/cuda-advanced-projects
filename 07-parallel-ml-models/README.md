# CUDA Parallel ML Models - Paralel Makine Ã–ÄŸrenmesi Modelleri

## ğŸ¯ Proje AmacÄ±

Bu proje, **CUDA kullanarak iki farklÄ± makine Ã¶ÄŸrenmesi modelinin paralel olarak eÄŸitilmesini** gÃ¶sterir. Proje, GPU programlama ve paralel iÅŸleme kavramlarÄ±nÄ± Ã¶ÄŸrenmek isteyenler iÃ§in tasarlanmÄ±ÅŸtÄ±r.

### KullanÄ±lan Modeller:
1. **Linear Regression (DoÄŸrusal Regresyon)** - En uygun doÄŸru Ã§izgisini bulma
2. **K-Means Clustering** - Verileri kÃ¼melere ayÄ±rma

## ğŸš€ Ã–ne Ã‡Ä±kan Ã–zellikler

- âœ… **Tam CUDA implementasyonu** - Her model GPU Ã¼zerinde Ã§alÄ±ÅŸÄ±r
- âœ… **Paralel eÄŸitim** - Ä°ki model aynÄ± anda, farklÄ± CUDA stream'lerinde eÄŸitilir
- âœ… **OpenGL gÃ¶rselleÅŸtirme** - GerÃ§ek zamanlÄ± sonuÃ§ gÃ¶rÃ¼ntÃ¼leme
- âœ… **Modern C++17** ve CUDA
- âœ… **CMake build sistemi**

## ğŸ“Š Modeller HakkÄ±nda

### 1. Linear Regression (DoÄŸrusal Regresyon)

**Ne yapar?**
- Verilen noktalara en uygun doÄŸru Ã§izgisini bulur
- FormÃ¼l: `y = mx + b` (m: eÄŸim, b: kesiÅŸim noktasÄ±)

**CUDA ParalelleÅŸtirmesi:**
- Her Ã¶rnek iÃ§in tahmin hesaplama paralel
- Gradient hesaplama paralel
- AÄŸÄ±rlÄ±k gÃ¼ncelleme paralel

**Kernel'ler:**
- `predictKernel`: y_pred = w*x + b hesaplar
- `computeGradientsKernel`: Gradientleri hesaplar
- `updateWeightsKernel`: AÄŸÄ±rlÄ±klarÄ± gÃ¼nceller
- `computeLossKernel`: MSE loss'u hesaplar (shared memory reduction ile)

### 2. K-Means Clustering

**Ne yapar?**
- Verileri benzerliklerine gÃ¶re K tane kÃ¼meye ayÄ±rÄ±r
- Her kÃ¼menin bir merkez noktasÄ± (centroid) vardÄ±r

**CUDA ParalelleÅŸtirmesi:**
- Her veri noktasÄ± iÃ§in en yakÄ±n merkezi bulma paralel
- Yeni merkezleri hesaplama paralel
- Inertia (kÃ¼me iÃ§i mesafe toplamÄ±) hesaplama paralel

**Kernel'ler:**
- `assignClustersKernel`: Her noktayÄ± en yakÄ±n kÃ¼meye atar
- `updateCentroidsKernel`: Yeni kÃ¼me merkezlerini hesaplar
- `computeInertiaKernel`: Toplam kÃ¼me iÃ§i mesafeyi hesaplar

## ğŸ”§ Kurulum

### Gereksinimler

- CUDA Toolkit (11.0+)
- CMake (3.18+)
- C++17 uyumlu derleyici (GCC 9+, Clang 10+)
- OpenGL
- GLEW
- GLFW3
- NVIDIA GPU (Compute Capability 7.5+)

### Ubuntu/Debian Kurulumu

```bash
# CUDA Toolkit yÃ¼klÃ¼ olduÄŸunu varsayÄ±yoruz
sudo apt update
sudo apt install cmake build-essential
sudo apt install libglew-dev libglfw3-dev libgl1-mesa-dev
```

### Derleme

```bash
cd 07-parallel-ml-models
mkdir build && cd build
cmake ..
make -j$(nproc)
```

## ğŸ® Ã‡alÄ±ÅŸtÄ±rma

```bash
./parallel_ml_models
```

### Beklenen Ã‡Ä±ktÄ±

Program Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda:
1. Model parametreleri baÅŸlatÄ±lÄ±r
2. EÄŸitim verisi oluÅŸturulur
3. Ä°ki model paralel olarak eÄŸitilir (farklÄ± thread'lerde)
4. OpenGL penceresi aÃ§Ä±lÄ±r ve sonuÃ§lar gÃ¶rselleÅŸtirilir

**GÃ¶rselleÅŸtirme:**
- **Sol panel**: Linear Regression - Mavi noktalar (veri), kÄ±rmÄ±zÄ± Ã§izgi (model)
- **SaÄŸ panel**: K-Means - Renkli noktalar (veriler), beyaz merkezli noktalar (centroid'ler)

**Ã‡Ä±kmak iÃ§in:** ESC tuÅŸuna basÄ±n

## ğŸ“ Proje YapÄ±sÄ±

```
07-parallel-ml-models/
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ linear_regression.h    # Linear Regression model tanÄ±mÄ±
â”‚   â”œâ”€â”€ kmeans.h               # K-Means model tanÄ±mÄ±
â”‚   â”œâ”€â”€ model_manager.h        # Paralel eÄŸitim koordinatÃ¶rÃ¼
â”‚   â””â”€â”€ visualizer.h           # OpenGL gÃ¶rselleÅŸtirme
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ linear_regression.cu   # Linear Regression CUDA implementasyonu
â”‚   â”œâ”€â”€ kmeans.cu              # K-Means CUDA implementasyonu
â”‚   â”œâ”€â”€ model_manager.cpp      # Model koordinasyon kodu
â”‚   â”œâ”€â”€ visualizer.cpp         # GÃ¶rselleÅŸtirme kodu
â”‚   â””â”€â”€ main.cpp               # Ana program
â”œâ”€â”€ CMakeLists.txt
â””â”€â”€ README.md
```

## ğŸ§  Paralel Ä°ÅŸleme NasÄ±l Ã‡alÄ±ÅŸÄ±yor?

### 1. Thread-Level Parallelism (CPU)

```cpp
// Model Manager iÃ§inde
std::thread linearThread(&ModelManager::trainLinearModel, this);
std::thread kmeansThread(&ModelManager::trainKMeansModel, this);
```

Ä°ki ayrÄ± CPU thread'i, iki farklÄ± modeli eÄŸitir.

### 2. CUDA Stream-Level Parallelism (GPU)

Her model kendi CUDA stream'ini kullanÄ±r:

```cpp
cudaStream_t stream;
cudaStreamCreate(&stream);
// Kernel Ã§aÄŸrÄ±larÄ± bu stream Ã¼zerinde
kernel<<<grid, block, 0, stream>>>(...);
```

Bu sayede GPU, iki modelin kernel'lerini **aynÄ± anda** Ã§alÄ±ÅŸtÄ±rabilir!

### 3. GPU Parallelism (CUDA Kernels)

Her kernel iÃ§inde binlerce thread paralel Ã§alÄ±ÅŸÄ±r:

```cuda
__global__ void predictKernel(...) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < numSamples) {
        // Her thread bir Ã¶rneÄŸi iÅŸler
        predictions[idx] = compute(...);
    }
}
```

## ğŸ“ˆ Performans OptimizasyonlarÄ±

### 1. Shared Memory KullanÄ±mÄ±

Loss ve inertia hesaplamalarÄ±nda **reduction pattern** ile shared memory kullanÄ±lÄ±r:

```cuda
extern __shared__ float sharedData[];
// Her thread kendi sonucunu shared memory'e yazar
sharedData[tid] = localResult;
__syncthreads();
// Reduction ile toplam hesaplanÄ±r
```

### 2. Coalesced Memory Access

Veri dÃ¼zeni, GPU bellek eriÅŸimlerini optimize eder:
- ArdÄ±ÅŸÄ±k thread'ler ardÄ±ÅŸÄ±k bellek adreslerine eriÅŸir
- `X[idx * numFeatures + f]` dÃ¼zeni kullanÄ±lÄ±r

### 3. Asynchronous Operations

CPU-GPU veri transferi asenkron yapÄ±lÄ±r:

```cpp
cudaMemcpyAsync(..., cudaMemcpyHostToDevice, stream);
kernel<<<...>>>(...);
cudaMemcpyAsync(..., cudaMemcpyDeviceToHost, stream);
```

## ğŸ“ Ã–ÄŸrenme KaynaklarÄ±

### AnlaÅŸÄ±lmasÄ± Gereken Kavramlar:

1. **CUDA Threads ve Blocks**
   - Thread: GPU'da paralel Ã§alÄ±ÅŸan en kÃ¼Ã§Ã¼k birim
   - Block: Thread gruplarÄ±
   - Grid: Block gruplarÄ±

2. **Memory Hierarchy**
   - Global Memory: YavaÅŸ ama bÃ¼yÃ¼k
   - Shared Memory: HÄ±zlÄ± ama sÄ±nÄ±rlÄ±
   - Registers: En hÄ±zlÄ± ama Ã§ok sÄ±nÄ±rlÄ±

3. **Synchronization**
   - `__syncthreads()`: Block iÃ§i senkronizasyon
   - `cudaStreamSynchronize()`: Stream senkronizasyonu

4. **Gradient Descent**
   - Loss fonksiyonunu minimize etmek iÃ§in iteratif algoritma
   - Her iterasyonda: Forward pass â†’ Compute gradient â†’ Update weights

5. **K-Means Algorithm**
   - 1. AdÄ±m: Her noktayÄ± en yakÄ±n merkeze ata
   - 2. AdÄ±m: Yeni merkezleri hesapla
   - YakÄ±nsama olana kadar tekrarla

## ğŸ” Kod Ä°nceleme Ã–nerileri

1. **Ã–nce basit kernel'lere bakÄ±n:**
   - `predictKernel` (linear_regression.cu)
   - `assignClustersKernel` (kmeans.cu)

2. **Reduction pattern'i anlayÄ±n:**
   - `computeLossKernel` fonksiyonunu inceleyin
   - Shared memory kullanÄ±mÄ±nÄ± gÃ¶zlemleyin

3. **Paralel koordinasyonu inceleyin:**
   - `model_manager.cpp` dosyasÄ±ndaki thread yÃ¶netimi
   - CUDA stream kullanÄ±mÄ±

## ğŸ› Sorun Giderme

### CUDA Out of Memory
- Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n
- Daha az Ã¶rnek kullanÄ±n

### Derleme HatalarÄ±
- CUDA Toolkit kurulu mu kontrol edin: `nvcc --version`
- CMake versiyonu: `cmake --version` (3.18+ olmalÄ±)

### GÃ¶rselleÅŸtirme AÃ§Ä±lmÄ±yor
- OpenGL sÃ¼rÃ¼cÃ¼leri kurulu mu?
- `glxinfo | grep "OpenGL version"` ile kontrol edin

### DÃ¼ÅŸÃ¼k Performans
- GPU kullanÄ±mÄ±nÄ± kontrol edin: `nvidia-smi`
- Compute capability'nizi kontrol edin ve CMakeLists.txt'de ayarlayÄ±n

## ğŸ“ GeliÅŸtirme Fikirleri

1. **Daha fazla model ekleyin:**
   - Logistic Regression
   - Neural Network (basit MLP)
   - SVM (Support Vector Machine)

2. **Optimizasyon teknikleri:**
   - Mini-batch gradient descent
   - Momentum optimizer
   - Adam optimizer

3. **Daha iyi gÃ¶rselleÅŸtirme:**
   - Loss grafiÄŸi
   - Confusion matrix
   - 3D gÃ¶rselleÅŸtirme

4. **Model karÅŸÄ±laÅŸtÄ±rmasÄ±:**
   - EÄŸitim sÃ¼relerini Ã¶lÃ§Ã¼n
   - Accuracy karÅŸÄ±laÅŸtÄ±rmasÄ±
   - GPU vs CPU performans karÅŸÄ±laÅŸtÄ±rmasÄ±

## ğŸ“š Referanslar

- [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [CUDA Best Practices](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
- [Machine Learning on GPU](https://developer.nvidia.com/deep-learning)

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r ve serbestÃ§e kullanÄ±labilir.

## ğŸ‘¤ GeliÅŸtirici NotlarÄ±

Bu proje, CUDA programlama ve paralel makine Ã¶ÄŸrenmesinin temellerini Ã¶ÄŸretmek iÃ§in tasarlanmÄ±ÅŸtÄ±r. Kodlar **sadelik** ve **anlaÅŸÄ±labilirlik** gÃ¶z Ã¶nÃ¼nde bulundurularak yazÄ±lmÄ±ÅŸtÄ±r. Production ortamÄ±nda daha fazla optimizasyon ve hata kontrolÃ¼ gerekebilir.

**Keyifli Ã¶ÄŸrenmeler! ğŸš€**
